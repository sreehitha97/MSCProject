{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59c4f0b-a5bf-407a-9c92-b41c3de208b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing customer 3253926e-9c0d-4fd9-8248-eb7c2f457b99\n",
      "Error processing customer 3253926e-9c0d-4fd9-8248-eb7c2f457b99: name 'node_emissions' is not defined\n",
      "All customer results have been processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import pymfinder as py\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Load the transaction data\n",
    "df = pd.read_csv('./Debit_Transactions4.csv')\n",
    "\n",
    "# Extract relevant columns\n",
    "df = df[['customerId', 'externalParty.merchantCategoryCode', 'createdAt', 'transactionFootPrint.carbonEmissionInGrams']]\n",
    "\n",
    "# Convert 'createdAt' to datetime and sort by customer and timestamp\n",
    "df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "df = df.sort_values(by=['customerId', 'createdAt'])\n",
    "\n",
    "# Create transaction sequences by customer with carbon emissions\n",
    "transaction_sequences = df.groupby('customerId').apply(\n",
    "    lambda x: list(zip(x['externalParty.merchantCategoryCode'], x['transactionFootPrint.carbonEmissionInGrams']))\n",
    ").reset_index(name='sequences')\n",
    "\n",
    "# Initialize a dictionary to store results for each customer\n",
    "all_customer_results = {}\n",
    "\n",
    "# Mapping of motifs to their initial nodes\n",
    "initial_nodes = {\n",
    "    (6, 0, 1),    # S1\n",
    "    (12, 0, 1),   # S3\n",
    "    (14, 0, 1),   # S7\n",
    "    (36, 0, 2),   # S9\n",
    "    (38, 0, 1),   # S11\n",
    "    (46, 1, 1),   # S14 or S15 (both are initial and have the same structure)\n",
    "    (74, 0, 1),   # S16\n",
    "    (78, 0, 2),   # S19\n",
    "    (98, 0, 2),   # S21\n",
    "    (102, 0, 1),  # S23\n",
    "    (108, 1, 1),  # S25 or S26 (both are initial and have the same structure)\n",
    "    (238, 1, 1)   # S29 or S30 (both are initial and have the same structure)\n",
    "}\n",
    "\n",
    "# Convert initial_nodes to a set of motif IDs\n",
    "initial_node_ids = {id for id, *_ in initial_nodes}\n",
    "\n",
    "# Function to process a single customer\n",
    "def process_customer(customer_id, sequences):\n",
    "    G = nx.DiGraph()\n",
    "    edge_freq = defaultdict(int)\n",
    "    edge_emissions = defaultdict(float)\n",
    "    node_emissions = defaultdict(list)  # Store all emissions for calculating average\n",
    "\n",
    "    # Validate sequences format\n",
    "    if not isinstance(sequences, list):\n",
    "        raise TypeError(f\"Sequences for customer {customer_id} are not in the expected format: {type(sequences)}\")\n",
    "\n",
    "    # Add edges, their weights, and carbon emissions\n",
    "    for seq in sequences:\n",
    "        if not isinstance(seq, tuple) or len(seq) != 2:\n",
    "            raise ValueError(f\"Invalid sequence format for customer {customer_id}: {seq}\")\n",
    "        \n",
    "        node_id = seq[0]\n",
    "        emission = seq[1]\n",
    "        if pd.notna(emission):  # Check for NaN emissions\n",
    "            node_emissions[node_id].append(emission)  # Collect emissions for average calculation\n",
    "            # Add edges to the graph\n",
    "            for i in range(len(sequences) - 1):\n",
    "                source = sequences[i][0]\n",
    "                target = sequences[i + 1][0]\n",
    "                edge_freq[(source, target)] += 1\n",
    "                edge_emissions[(source, target)] += sequences[i + 1][1]\n",
    "\n",
    "    # Add edges to the graph with weights and emissions\n",
    "    for (source, target), weight in edge_freq.items():\n",
    "        emission = edge_emissions.get((source, target), 0)\n",
    "        G.add_edge(source, target, weight=weight, emissions=emission)\n",
    "\n",
    "    # Save the network to an edge list file (without emissions for pymfinder)\n",
    "    network_file = f'network_edges_{customer_id}.txt'\n",
    "    with open(network_file, 'w') as file:\n",
    "        for edge in G.edges(data=True):\n",
    "            source, target, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{source} {target} {weight}\\n\")\n",
    "\n",
    "    # Run pymfinder to detect motifs\n",
    "    results = py.pymfinder(\n",
    "        network=network_file,\n",
    "        links=True,\n",
    "        motifsize=3,\n",
    "        stoufferIDs=False,\n",
    "        allmotifs=False,\n",
    "        nrandomizations=0,\n",
    "        randomize=False,\n",
    "        usemetropolis=False,\n",
    "        networktype=\"unipartite\"\n",
    "    )\n",
    "\n",
    "    def node_link_to_dict(node_link):\n",
    "        return {\n",
    "            \"id\": node_link.id,\n",
    "            \"motifs\": node_link.motifs,\n",
    "            \"roles\": node_link.roles,\n",
    "            \"weight\": node_link.weight,\n",
    "            \"weighted_motifs\": node_link.weighted_motifs,\n",
    "            \"weighted_roles\": node_link.weighted_roles\n",
    "        }\n",
    "\n",
    "    # Extract the data to save\n",
    "    results_dict = {\n",
    "        \"motifs\": {motif_id: motif.real for motif_id, motif in results.motifs.items()},\n",
    "        \"nodes\": {\n",
    "            node_id: {\n",
    "                \"id\": node.id,\n",
    "                \"motifs\": node.motifs,\n",
    "                \"roles\": node.roles,\n",
    "                \"weighted_motifs\": node.weighted_motifs,\n",
    "                \"weighted_roles\": node.weighted_roles\n",
    "            } for node_id, node in results.nodes.items()\n",
    "        },\n",
    "        \"links\": [node_link_to_dict(link) for _, link in results.links.items()]  # Convert NodeLink to dict\n",
    "    }\n",
    "\n",
    "    # Function to convert tuple keys to strings\n",
    "    def convert_tuple_keys(d):\n",
    "        if isinstance(d, dict):\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                if isinstance(k, tuple):\n",
    "                    k = str(k)\n",
    "                new_dict[k] = convert_tuple_keys(v)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [convert_tuple_keys(i) for i in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    # Convert any tuple keys to strings\n",
    "    results_dict = convert_tuple_keys(results_dict)\n",
    "\n",
    "    # Save the results to a text file\n",
    "    results_file = f'results_{customer_id}.txt'\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results_dict, f, indent=4)\n",
    "\n",
    "    # Calculate total emission per motif\n",
    "    return calculate_total_emission_per_motif(G, results_dict['motifs'], results_dict['nodes'], results_dict['links'])\n",
    "\n",
    "# Function to calculate total emissions per motif for a customer\n",
    "def calculate_total_emission_per_motif(G, motifs, nodes, links):\n",
    "    motif_emissions = defaultdict(float)\n",
    "    added_nodes = defaultdict(set)\n",
    "    motif_link_counts = defaultdict(int)\n",
    " \n",
    "    # Create a dictionary to map links to their motifs\n",
    "    link_motifs = {tuple(link['id']): link['motifs'] for link in links}\n",
    "\n",
    "    # Function to convert role string to a tuple\n",
    "    def role_str_to_tuple(role_str):\n",
    "        return tuple(map(int, role_str.strip('()').split(', ')))\n",
    "\n",
    "    # Iterate through links to calculate emissions for each motif\n",
    "    for link in links:\n",
    "        edge_id = tuple(link['id'])\n",
    "        associated_motifs = link['motifs']\n",
    "        emission = G[edge_id[0]][edge_id[1]].get('emissions', 0)\n",
    "        weight = G[edge_id[0]][edge_id[1]].get('weight', 1)\n",
    "\n",
    "        for motif_id in associated_motifs:\n",
    "            count = link['motifs'][motif_id]\n",
    "            motif_link_counts[motif_id] += count\n",
    "            motif_id_int = int(motif_id)  # Ensure motif_id is an integer\n",
    "            # Determine the multiplier based on the motif ID\n",
    "            multiplier = 2 if motif_id_int in {36, 78} else 1\n",
    "\n",
    "            if motif_id_int in initial_node_ids:\n",
    "                # Convert node IDs to string format to access the nodes dictionary\n",
    "                node_id_str_1 = edge_id[0]\n",
    "                node_id_str_2 = edge_id[1]\n",
    "\n",
    "                # Check if node_id_str_1 is in nodes by comparing `id`\n",
    "                node_in_nodes = next((node for node in nodes.values() if node['id'] == int(node_id_str_1)), None)\n",
    "                \n",
    "                if node_in_nodes:\n",
    "                    # Get roles with count > 0\n",
    "                    node_roles = {role: count for role, count in node_in_nodes['roles'].items() if count > 0}\n",
    "                    # Convert roles to tuples for comparison\n",
    "                    node_roles_tuples = {role_str_to_tuple(role) for role in node_roles}\n",
    "                    # Check if any role matches the initial node role for the motif\n",
    "                    for role_tuple in node_roles_tuples:\n",
    "                        if role_tuple in initial_nodes:\n",
    "                            if not (edge_id[0] in added_nodes[motif_id_int]):\n",
    "                                # Calculate initial emission\n",
    "                                if (role_tuple[0] == motif_id_int):\n",
    "                                    initial_emission = sum(node_emissions.get(edge_id[0], [])) / len(node_emissions[edge_id[0]])\n",
    "                                    initial_emission *= node_roles.get(str(role_tuple), 0)  # Multiply by count\n",
    "                                    initial_emission *= multiplier\n",
    "                                    motif_emissions[motif_id_int] += initial_emission\n",
    "                                    added_nodes[motif_id_int].add(edge_id[0])\n",
    "\n",
    "            # Accumulate emission for the motif, but only if it's a valid number\n",
    "            if not math.isnan(emission):\n",
    "                motif_emissions[motif_id_int] += emission * (link['motifs'][motif_id] / weight)\n",
    "  \n",
    "    # Return results\n",
    "    return motif_emissions\n",
    "\n",
    "# Process each customer and store results\n",
    "for customer_id, sequences in transaction_sequences.values:\n",
    "    print(f\"Processing customer {customer_id}\")\n",
    "    try:\n",
    "        customer_results = process_customer(customer_id, sequences)\n",
    "        all_customer_results[customer_id] = customer_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing customer {customer_id}: {e}\")\n",
    "\n",
    "# Save all results to a file\n",
    "with open('all_customer_results.json', 'w') as f:\n",
    "    json.dump(all_customer_results, f, indent=4)\n",
    "\n",
    "print(\"All customer results have been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400ca5a1-7277-4d26-999c-88749fe5c4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing customer 2aa2a980-470d-470a-8379-ec51e5036ee4\n",
      "Processing customer 3253926e-9c0d-4fd9-8248-eb7c2f457b99\n",
      "All customer results have been processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import pymfinder as py\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Load the transaction data\n",
    "df = pd.read_csv('./Debit_Transactions4.csv')\n",
    "\n",
    "# Extract relevant columns\n",
    "df = df[['customerId', 'externalParty.merchantCategoryCode', 'createdAt', 'transactionFootPrint.carbonEmissionInGrams']]\n",
    "\n",
    "# Convert 'createdAt' to datetime and sort by customer and timestamp\n",
    "df['createdAt'] = pd.to_datetime(df['createdAt'])\n",
    "df = df.sort_values(by=['customerId', 'createdAt'])\n",
    "\n",
    "# Create transaction sequences by customer with carbon emissions\n",
    "transaction_sequences = df.groupby('customerId').apply(\n",
    "    lambda x: list(zip(x['externalParty.merchantCategoryCode'], x['transactionFootPrint.carbonEmissionInGrams']))\n",
    ").reset_index(name='sequences')\n",
    "\n",
    "# Initialize a dictionary to store results for each customer\n",
    "all_customer_results = {}\n",
    "\n",
    "# Mapping of motifs to their initial nodes\n",
    "initial_nodes = {\n",
    "    (6, 0, 1),    # S1\n",
    "    (12, 0, 1),   # S3\n",
    "    (14, 0, 1),   # S7\n",
    "    (36, 0, 2),   # S9\n",
    "    (38, 0, 1),   # S11\n",
    "    (46, 1, 1),   # S14 or S15 (both are initial and have the same structure)\n",
    "    (74, 0, 1),   # S16\n",
    "    (78, 0, 2),   # S19\n",
    "    (98, 0, 2),   # S21\n",
    "    (102, 0, 1),  # S23\n",
    "    (108, 1, 1),  # S25 or S26 (both are initial and have the same structure)\n",
    "    (238, 1, 1)   # S29 or S30 (both are initial and have the same structure)\n",
    "}\n",
    "\n",
    "# Convert initial_nodes to a set of motif IDs\n",
    "initial_node_ids = {id for id, *_ in initial_nodes}\n",
    "# Function to process a single customer\n",
    "def process_customer(customer_id, sequences):\n",
    "    G = nx.DiGraph()\n",
    "    edge_freq = defaultdict(int)\n",
    "    edge_emissions = defaultdict(float)\n",
    "    node_emissions = defaultdict(list)  # Store all emissions for calculating average\n",
    "\n",
    "    # Validate sequences format\n",
    "    if not isinstance(sequences, list):\n",
    "        raise TypeError(f\"Sequences for customer {customer_id} are not in the expected format: {type(sequences)}\")\n",
    "\n",
    "    # Add edges, their weights, and carbon emissions\n",
    "    for seq in sequences:\n",
    "        if not isinstance(seq, tuple) or len(seq) != 2:\n",
    "            raise ValueError(f\"Invalid sequence format for customer {customer_id}: {seq}\")\n",
    "        \n",
    "        node_id = seq[0]\n",
    "        emission = seq[1]\n",
    "        if pd.notna(emission):  # Check for NaN emissions\n",
    "            node_emissions[node_id].append(emission)  # Collect emissions for average calculation\n",
    "            # Add edges to the graph\n",
    "            for i in range(len(sequences) - 1):\n",
    "                source = sequences[i][0]\n",
    "                target = sequences[i + 1][0]\n",
    "                edge_freq[(source, target)] += 1\n",
    "                edge_emissions[(source, target)] += sequences[i + 1][1]\n",
    "\n",
    "    # Add edges to the graph with weights and emissions\n",
    "    for (source, target), weight in edge_freq.items():\n",
    "        emission = edge_emissions.get((source, target), 0)\n",
    "        G.add_edge(source, target, weight=weight, emissions=emission)\n",
    "\n",
    "    # Save the network to an edge list file (without emissions for pymfinder)\n",
    "    network_file = f'network_edges_{customer_id}.txt'\n",
    "    with open(network_file, 'w') as file:\n",
    "        for edge in G.edges(data=True):\n",
    "            source, target, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{source} {target} {weight}\\n\")\n",
    "\n",
    "    def node_link_to_dict(node_link):\n",
    "        return {\n",
    "            \"id\": node_link.id,\n",
    "            \"motifs\": node_link.motifs,\n",
    "            \"roles\": node_link.roles,\n",
    "            \"weight\": node_link.weight,\n",
    "            \"weighted_motifs\": node_link.weighted_motifs,\n",
    "            \"weighted_roles\": node_link.weighted_roles\n",
    "        }\n",
    "\n",
    "    # Run pymfinder to detect motifs\n",
    "    results = py.pymfinder(\n",
    "        network=network_file,\n",
    "        links=True,\n",
    "        motifsize=3,\n",
    "        stoufferIDs=False,\n",
    "        allmotifs=False,\n",
    "        nrandomizations=0,\n",
    "        randomize=False,\n",
    "        usemetropolis=False,\n",
    "        networktype=\"unipartite\"\n",
    "    )\n",
    "\n",
    "    # Extract the data to save\n",
    "    results_dict = {\n",
    "        \"motifs\": {motif_id: motif.real for motif_id, motif in results.motifs.items()},\n",
    "        \"nodes\": {\n",
    "            node_id: {\n",
    "                \"id\": node.id,\n",
    "                \"motifs\": node.motifs,\n",
    "                \"roles\": node.roles,\n",
    "                \"weighted_motifs\": node.weighted_motifs,\n",
    "                \"weighted_roles\": node.weighted_roles\n",
    "            } for node_id, node in results.nodes.items()\n",
    "        },\n",
    "        \"links\": [node_link_to_dict(link) for _, link in results.links.items()]  # Convert NodeLink to dict\n",
    "    }\n",
    "\n",
    "    # Function to convert tuple keys to strings\n",
    "    def convert_tuple_keys(d):\n",
    "        if isinstance(d, dict):\n",
    "            new_dict = {}\n",
    "            for k, v in d.items():\n",
    "                if isinstance(k, tuple):\n",
    "                    k = str(k)\n",
    "                new_dict[k] = convert_tuple_keys(v)\n",
    "            return new_dict\n",
    "        elif isinstance(d, list):\n",
    "            return [convert_tuple_keys(i) for i in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    # Convert any tuple keys to strings\n",
    "    results_dict = convert_tuple_keys(results_dict)\n",
    "\n",
    "    # Save the results to a text file\n",
    "    results_file = f'results_{customer_id}.txt'\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results_dict, f, indent=4)\n",
    "\n",
    "    # Calculate total emission per motif\n",
    "    return calculate_total_emission_per_motif(G, results_dict['motifs'], results_dict['nodes'], results_dict['links'], node_emissions)\n",
    "\n",
    "# Function to calculate total emissions per motif for a customer\n",
    "def calculate_total_emission_per_motif(G, motifs, nodes, links, node_emissions):\n",
    "    motif_emissions = defaultdict(float)\n",
    "    added_nodes = defaultdict(set)\n",
    "    motif_link_counts = defaultdict(int)\n",
    " \n",
    "    # Create a dictionary to map links to their motifs\n",
    "    link_motifs = {tuple(link['id']): link['motifs'] for link in links}\n",
    "\n",
    "    # Function to convert role string to a tuple\n",
    "    def role_str_to_tuple(role_str):\n",
    "        return tuple(map(int, role_str.strip('()').split(', ')))\n",
    "\n",
    "    # Iterate through links to calculate emissions for each motif\n",
    "    for link in links:\n",
    "        edge_id = tuple(link['id'])\n",
    "        associated_motifs = link['motifs']\n",
    "        emission = G[edge_id[0]][edge_id[1]].get('emissions', 0)\n",
    "        weight = G[edge_id[0]][edge_id[1]].get('weight', 1)\n",
    "\n",
    "        for motif_id in associated_motifs:\n",
    "            count = link['motifs'][motif_id]\n",
    "            motif_link_counts[motif_id] += count\n",
    "            motif_id_int = int(motif_id)  # Ensure motif_id is an integer\n",
    "            # Determine the multiplier based on the motif ID\n",
    "            multiplier = 2 if motif_id_int in {36, 78} else 1\n",
    "\n",
    "            if motif_id_int in initial_node_ids:\n",
    "                # Convert node IDs to string format to access the nodes dictionary\n",
    "                node_id_str_1 = edge_id[0]\n",
    "                node_id_str_2 = edge_id[1]\n",
    "\n",
    "                # Check if node_id_str_1 is in nodes by comparing `id`\n",
    "                node_in_nodes = next((node for node in nodes.values() if node['id'] == int(node_id_str_1)), None)\n",
    "                \n",
    "                if node_in_nodes:\n",
    "                    # Get roles with count > 0\n",
    "                    node_roles = {role: count for role, count in node_in_nodes['roles'].items() if count > 0}\n",
    "                    # Convert roles to tuples for comparison\n",
    "                    node_roles_tuples = {role_str_to_tuple(role) for role in node_roles}\n",
    "                    # Check if any role matches the initial node role for the motif\n",
    "                    for role_tuple in node_roles_tuples:\n",
    "                        if role_tuple in initial_nodes:\n",
    "                            if not (edge_id[0] in added_nodes[motif_id_int]):\n",
    "                                # Calculate initial emission\n",
    "                                if (role_tuple[0] == motif_id_int):\n",
    "                                    initial_emission = sum(node_emissions.get(edge_id[0], [])) / len(node_emissions.get(edge_id[0], [1]))\n",
    "                                    initial_emission *= node_roles.get(str(role_tuple), 0)  # Multiply by count\n",
    "                                    initial_emission *= multiplier\n",
    "                                    motif_emissions[motif_id_int] += initial_emission\n",
    "                                    added_nodes[motif_id_int].add(edge_id[0])\n",
    "\n",
    "            # Accumulate emission for the motif, but only if it's a valid number\n",
    "            if not math.isnan(emission):\n",
    "                motif_emissions[motif_id_int] += emission * (link['motifs'][motif_id] / weight)\n",
    "  \n",
    "    # Return results\n",
    "    return motif_emissions\n",
    "\n",
    "# Process each customer and store results\n",
    "for customer_id, sequences in transaction_sequences.values:\n",
    "    print(f\"Processing customer {customer_id}\")\n",
    "    try:\n",
    "        customer_results = process_customer(customer_id, sequences)\n",
    "        all_customer_results[customer_id] = customer_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing customer {customer_id}: {e}\")\n",
    "\n",
    "# Save all results to a file\n",
    "with open('all_customer_results.json', 'w') as f:\n",
    "    json.dump(all_customer_results, f, indent=4)\n",
    "\n",
    "print(\"All customer results have been processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c6b9c-8e29-498f-b948-c26239f42f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
